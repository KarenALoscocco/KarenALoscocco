pwd
setwd("~/Documents/GitHub/projects/Regression_Analysis_on_NYC_Airbnb_Data/code")
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
library(car)
library(leaps)
library(MASS)
setwd("~/Documents/GitHub/projects/Regression_Analysis_on_NYC_Airbnb_Data/code")
project_data = read.csv("AB_NYC_2019.csv")
nrow(project_data)
project_data = na.omit(project_data)
nrow(project_data)
data_sample = project_data[sample(nrow(project_data),
nrow(project_data)*(5000/nrow(project_data))),]
setwd("~/Documents/GitHub/projects/Regression_Analysis_on_NYC_Airbnb_Data/code")
project_data_sample = read_excel("sample_data.xlsx")
attach(project_data_sample)
setwd("~/Documents/GitHub/projects/Regression_Analysis_on_NYC_Airbnb_Data/code")
project_data_sample = read_excel("sample_data.xlsx")
attach(project_data_sample)
df = project_data_sample[c("price","minimum_nights","number_of_reviews","reviews_per_month"
,"calculated_host_listings_count","availability_365")]
cor(df)
basemodel = lm(price~minimum_nights+number_of_reviews+reviews_per_month
+calculated_host_listings_count+availability_365)
summary(basemodel)
vif(basemodel)
all_model<-regsubsets(price~.,data=df,nbest=2,method = "exhaustive")
all_sum = summary(all_model)
Rsq = round(all_sum$rsq*100, digit=1)
adj_Rsq = round(all_sum$adjr2*100, digit=1)
Cp = round(all_sum$cp, digit=1)
SSE = all_sum$rss
k = as.numeric(rownames(all_sum$which))
n = all_model$nn
S = round(sqrt(all_sum$rss/(n-(k+1))), digit=2)
SSTO = sum((price - mean(price))^2)
aic = round(2*(k+1)+n*log(SSE/n),digits=2)
SSE = round(SSE,digits=2)
cbind(Rsq, adj_Rsq, Cp, S, all_sum$outmat)
full.lm <- lm(price ~ . , data=df)
min.lm <- lm(price ~ 1, data=df)
step_both = step(min.lm, list(upper=full.lm), direction='both')
bestmodel= lm(price~number_of_reviews+reviews_per_month+calculated_host_listings_count
+availability_365 + minimum_nights)
qqnorm(resid(bestmodel),pch=16,main="Normal Probability Plot of Residuals")
qqline(resid(bestmodel),col='red',lwd=2)
plot(fitted(bestmodel),resid(bestmodel), pch=16, col="blue", ylab=bquote(paste("e")),
xlab=bquote(paste("Fitted Values")),main="Plot of e vs Fitted Values")
abline(0,0,col="red",lwd=3)
plot(number_of_reviews,resid(bestmodel), pch=16, col="blue", ylab=bquote(paste("e")),
xlab=bquote(paste("number of reviews")),main="Plot of e vs number of reviews")
abline(0,0,col="red",lwd=3)
plot(reviews_per_month,resid(bestmodel), pch=16, col="blue", ylab=bquote(paste("e")),
xlab=bquote(paste("reviews per month")),main="reviews per month")
abline(0,0,col="red",lwd=3)
k = 5
n = length(price)
LV_cutoff = 2*(k+1)/n; print(LV_cutoff)
Hi = hatvalues(bestmodel)
Hi[Hi>LV_cutoff]
Res_SE = summary(bestmodel)$sigma
di = resid(bestmodel)/(1-Hi)
SSE = Res_SE^2*(n-(k+1))
SDR = resid(bestmodel)*sqrt((n-k-2)/(SSE*(1-Hi)-(resid(bestmodel))^2))
SDR[abs(SDR)>qt(0.975,n-k-2)] #some evidence
SDR[abs(SDR)>qt(0.995,n-k-2)] #strong evidence
CooksD = cooks.distance(bestmodel)
CooksD[CooksD>qf(0.5,k+1, n-k-1)] #Influential
#CooksD[CooksD<qf(0.2,k+1, n-k-1)] #Not Influential
CooksD[CooksD<qf(0.5,k+1, n-k-1) & CooksD>qf(0.2,k+1, n-k-1)]
attach(project_data_sample)
brooklyn_dummy = as.numeric(neighbourhood_group == 'Brooklyn')
queens_dummy = as.numeric(neighbourhood_group == 'Queens')
bronx_dummy = as.numeric(neighbourhood_group == 'Bronx')
staten_dummy = as.numeric(neighbourhood_group == 'Staten Island')
private_room_dummy = as.numeric(room_type =='Private room')
shared_room_dummy = as.numeric(room_type == 'Shared room')
location_price_model = lm(price ~ + brooklyn_dummy +
queens_dummy + bronx_dummy + staten_dummy)
summary(location_price_model)
anova(location_price_model)
staten_model = lm(price~staten_dummy)
summary(staten_model)
anova(staten_model)
overall = lm(price ~number_of_reviews + minimum_nights + reviews_per_month
+ calculated_host_listings_count+ availability_365 + shared_room_dummy
+ staten_dummy+ brooklyn_dummy + queens_dummy + bronx_dummy + private_room_dummy)
full.lm = lm(price ~ number_of_reviews + minimum_nights + reviews_per_month
+ calculated_host_listings_count +availability_365 + shared_room_dummy
+ staten_dummy+ brooklyn_dummy + queens_dummy + bronx_dummy
+ private_room_dummy, data = project_data_sample)
summary(full.lm)
vif(full.lm)
qqnorm(resid(full.lm),pch=16,main="Normal Probability Plot of Residuals")
qqline(resid(full.lm),col='red',lwd=2)
plot(fitted(full.lm),resid(full.lm), pch=16, col="blue", ylab=bquote(paste("e")),
xlab=bquote(paste("Fitted Values")),main="Plot of e vs Fitted Values")
abline(0,0,col="red",lwd=3)
plot(number_of_reviews,resid(full.lm), pch=16, col="blue", ylab=bquote(paste("e")),
xlab=bquote(paste("number of reviews")),main="Plot of e vs number of reviews")
abline(0,0,col="red",lwd=3)
plot(reviews_per_month,resid(full.lm), pch=16, col="blue", ylab=bquote(paste("e")),
xlab=bquote(paste("reviews per month")),main="reviews per month")
abline(0,0,col="red",lwd=3)
k = 7
n = length(price)
LV_cutoff = 2*(k+1)/n; print(LV_cutoff)
Hi = hatvalues(full.lm)
Hi[Hi>LV_cutoff]
Res_SE = summary(full.lm)$sigma
di = resid(full.lm)/(1-Hi)
SSE = Res_SE^2*(n-(k+1))
SDR = resid(full.lm)*sqrt((n-k-2)/(SSE*(1-Hi)-(resid(full.lm))^2))
SDR[abs(SDR)>qt(0.975,n-k-2)] #some evidence
SDR[abs(SDR)>qt(0.995,n-k-2)] #strong evidence
CooksD = cooks.distance(full.lm)
CooksD[CooksD>qf(0.5,k+1, n-k-1)] #Influential
#CooksD[CooksD<qf(0.2,k+1, n-k-1)] #Not Influential
CooksD[CooksD<qf(0.5,k+1, n-k-1) & CooksD>qf(0.2,k+1, n-k-1)]
min.lm = lm(price ~1, data = project_data_sample)
step_both = step(min.lm, list(upper = full.lm), direction = 'both')
newbestmodel= lm(price ~ private_room_dummy + availability_365 +
shared_room_dummy + brooklyn_dummy + bronx_dummy +
number_of_reviews + minimum_nights + queens_dummy +
staten_dummy)
qqnorm(resid(newbestmodel),pch=16,main="Normal Probability Plot of Residuals")
qqline(resid(newbestmodel),col='red',lwd=2)
summary(newbestmodel)
k = 7
n = length(price)
LV_cutoff = 2*(k+1)/n; print(LV_cutoff)
Hi = hatvalues(newbestmodel)
Hi[Hi>LV_cutoff]
Res_SE = summary(newbestmodel)$sigma
di = resid(newbestmodel)/(1-Hi)
SSE = Res_SE^2*(n-(k+1))
SDR = resid(newbestmodel)*sqrt((n-k-2)/(SSE*(1-Hi)-(resid(newbestmodel))^2))
SDR[abs(SDR)>qt(0.975,n-k-2)] #some evidence
SDR[abs(SDR)>qt(0.995,n-k-2)] #strong evidence
CooksD = cooks.distance(newbestmodel)
CooksD[CooksD>qf(0.5,k+1, n-k-1)] #Influential
#CooksD[CooksD<qf(0.2,k+1, n-k-1)] #Not Influential
CooksD[CooksD<qf(0.5,k+1, n-k-1) & CooksD>qf(0.2,k+1, n-k-1)]
library(ggmap)
library(dplyr)
library("ggcorrplot")
library(gridExtra)
#library(ggplot)
library(plotrix)
register_google("AIzaSyBizy0qq2Lq2IHZqp76GfUq6VSb5er4pt0")
pink = "#f547c1"
orange = "#f59847"
yellow = "#f5de47"
green = "#3dcc64"
blue = "#4fc7ff"
customcolors = c(pink,orange,green,blue,yellow)
airbnb = read.csv("AB_NYC_2019.csv")
attach(airbnb)
histdata = airbnb[airbnb$price <= 5000,]
ggplot(histdata, aes(histdata$price, fill = histdata$neighbourhood_group)) +
geom_histogram(binwidth = 25, size = 2) +
scale_fill_manual(values=customcolors) +
labs(x = "Price", y = "Number of Data Points", fill="Neighbourhood Group")
#ggsave("Hist_Price_NG_Before Random Sampling.png", dpi=1000)
data_sample_final = read.csv('sample_data.csv')
data_sample_final = read.csv('sample_data.csv')
data_sample_final = data_sample_final[,c(6:13,15:17)]
corr_data = data_sample_final[,c(1,3:11)]
corr_data = data.frame(corr_data)
corr <- round(cor(corr_data[,c(2,3,5,6,7,8,9,10)]),2)
ggcorrplot(corr, p.mat = cor_pmat(corr_data[,c(2,3,5,6,7,8,9,10)]),
hc.order = TRUE, type = "lower",
color = c(orange, "white", blue),
outline.col = "white",
lab = TRUE)
#ggsave("corr_matrix.png", dpi=1000)
counts = count(data_sample_final, neighbourhood_group)
ggplot(counts, aes(x = counts$neighbourhood_group, y = counts$n, fill = counts$neighbourhood_group, label = counts$n)) +
geom_bar(stat = "identity") +
geom_text(size = 2, position = position_stack(vjust = 0.5)) +
scale_fill_manual(values=customcolors) +
labs(x = "Neighbourhood Group", y = "Number of Data Points", fill="Neighbourhood Group")
#ggsave("num_of_room_type.png", dpi=1000)
histdata = data_sample_final
ggplot(histdata, aes(histdata$price, fill = histdata$neighbourhood_group)) +
geom_histogram(binwidth = 25, size = 2) +
scale_fill_manual(values=customcolors) +
labs(x = "Price", y = "Number of Data Points", fill="Neighbourhood Group")
#ggsave("Hist_Price_NG.png", dpi=1000)
histdata = data_sample_final[data_sample_final$price >= 1000,]
ggplot(histdata, aes(histdata$price, fill = histdata$neighbourhood_group)) +
geom_histogram(binwidth = 25, size = 2) +
scale_fill_manual(values=customcolors) +
labs(x = "Price", y = "Number of Data Points", fill="Neighbourhood Group")
#ggsave("Hist_Price_gt_1000_NG.png", dpi=1000)
histdata = data_sample_final[data_sample_final$price <= 1000,]
ggplot(histdata, aes(histdata$price, fill = histdata$neighbourhood_group)) +
geom_histogram(binwidth = 25, size = 2) +
scale_fill_manual(values=customcolors) +
labs(x = "Price", y = "Number of Data Points", fill="Neighbourhood Group")
#ggsave("Hist_Price_lt_1000_NG.png", dpi=1000)
# lat/long centers
ALL_centerlong = (min(data_sample_final$longitude) + max(data_sample_final$longitude))/2
ALL_centerlat = (min(data_sample_final$latitude) + max(data_sample_final$latitude))/2
# neighbourhood group centers
NG_centerlong = c()
NG_centerlat = c()
neighbourhood_groups = as.character(unique(data_sample_final$neighbourhood_group))
for (i in 1:length(neighbourhood_groups)) {
lat = data_sample_final$latitude[data_sample_final$neighbourhood_group == neighbourhood_groups[i]]
long = data_sample_final$longitude[data_sample_final$neighbourhood_group == neighbourhood_groups[i]]
NG_centerlong[i] = (min(long) + max(long))/2
NG_centerlat[i] = (min(lat) + max(lat))/2
}
NG_centers = data.frame(neighbourhood_groups, NG_centerlong, NG_centerlat)
#neighbourhood centers
N_centerlong = c()
N_centerlat = c()
neighbourhoods = as.character(unique(data_sample_final$neighbourhood))
for (i in 1:length(neighbourhoods)) {
lat = data_sample_final$latitude[data_sample_final$neighbourhood == neighbourhoods[i]]
long = data_sample_final$longitude[data_sample_final$neighbourhood == neighbourhoods[i]]
N_centerlong[i] = (min(long) + max(long))/2
N_centerlat[i] = (min(lat) + max(lat))/2
}
N_centers = data.frame(neighbourhoods, N_centerlong, N_centerlat)
map = get_map(location = c(ALL_centerlong, ALL_centerlat),
source = "google",
zoom = 10,
maptype = "roadmap",
size = c(640, 640),
scale = 2)
map = get_map(location = c(ALL_centerlong, ALL_centerlat),
source = "google",
zoom = 10,
maptype = "roadmap",
size = c(640, 640),
scale = 2)
map = get_map(location = c(ALL_centerlong, ALL_centerlat),
source = "google",
zoom = 10,
maptype = "roadmap",
size = c(640, 640),
scale = 2)
map = get_map(location = c(ALL_centerlong, ALL_centerlat),
source = "google",
zoom = 10,
maptype = "roadmap",
size = c(640, 640),
scale = 2)
map = get_map(location = c(ALL_centerlong, ALL_centerlat),
source = "google",
zoom = 10,
maptype = "roadmap",
size = c(640, 640),
scale = 2)
map = get_map(location = c(ALL_centerlong, ALL_centerlat),
source = "google",
zoom = 10,
maptype = "roadmap",
size = c(640, 640),
scale = 2)
map = get_map(location = c(ALL_centerlong, ALL_centerlat),
source = "google",
zoom = 10,
maptype = "roadmap",
size = c(640, 640),
scale = 2)
map = get_map(location = c(ALL_centerlong, ALL_centerlat),
source = "google",
zoom = 10,
maptype = "roadmap",
size = c(640, 640),
scale = 2)
map = get_map(location = c(ALL_centerlong, ALL_centerlat),
source = "google",
zoom = 10,
maptype = "roadmap",
size = c(640, 640),
scale = 2)
counts = count(data_sample_final, room_type)
ggplot(counts, aes(x = counts$room_type, y = counts$n, fill = counts$room_type, label = counts$n)) +
geom_bar(stat = "identity") +
geom_text(size = 2, position = position_stack(vjust = 0.5)) +
labs(x = "Room Type", y = "Number of Data Points", fill="Room Type")
#ggsave("num_of_Room_type.png", dpi=1000)
counts = count(data_sample_final, neighbourhood_group, neighbourhood)
counts[order(counts$neighbourhood_group, counts$neighbourhood, -counts$n),]
brooklyn = counts[counts$neighbourhood_group == 'Brooklyn',]
manhattan = counts[counts$neighbourhood_group == 'Manhattan',]
queens = counts[counts$neighbourhood_group == 'Queens',]
statenIsland = counts[counts$neighbourhood_group == 'Staten Island',]
bronx = counts[counts$neighbourhood_group == 'Bronx',]
nsi = statenIsland[order(statenIsland$neighbourhood_group, -statenIsland$n),][1:10,]
nq = queens[order(queens$neighbourhood_group, -queens$n),][1:10,]
nm = manhattan[order(manhattan$neighbourhood_group, -manhattan$n),][1:10,]
nbn = brooklyn[order(brooklyn$neighbourhood_group, -brooklyn$n),][1:10,]
nbx = bronx[order(bronx$neighbourhood_group, -bronx$n),][1:10,]
top10 = rbind(nsi,nq,nm,nbn,nbx)
histdata = data_sample_final[data_sample_final$neighbourhood == top10$neighbourhood,]
histdata = histdata[histdata$price <= 1000,]
ggplot(histdata, aes(x=histdata$neighbourhood, y=histdata$price, fill = histdata$neighbourhood_group)) +
geom_bar(stat = "identity") +
facet_wrap(~histdata$neighbourhood_group) +
scale_fill_manual(values=customcolors) +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
data = data_sample_final[data_sample_final$price<=1000,]
map = get_map(location = c(ALL_centerlong, ALL_centerlat),
source = "google",
zoom = 10,
maptype = "roadmap",
size = c(640, 640),
scale = 2)
data = data_sample_final
map = get_map(location = c(ALL_centerlong, ALL_centerlat),
source = "google",
zoom = 10,
maptype = "roadmap",
size = c(640, 640),
scale = 2)
data = data_sample_final
map = get_map(location = c(ALL_centerlong, ALL_centerlat),
source = "google",
zoom = 10,
maptype = "roadmap",
size = c(640, 640),
scale = 2)
histdata = data_sample_final
ggplot(histdata, aes(histdata$minimum_nights, fill = histdata$room_type)) +
geom_histogram(binwidth = 25, size = 2) +
labs(x = "Amount of Nights Minimum", y = "Number of Data Points", fill="Room Type")
#ggsave("Hist_MinNights_RoomType.png", dpi=1000)
data = data_sample_final[data_sample_final$minimum_nights <= 10,]
ggplot(data, aes(x=data$room_type, y=data$minimum_nights, fill=data$room_type)) +
geom_boxplot() +
coord_flip() +
labs(x = "Amount of Nights Minimum", y = "Number of Data Points", fill="Room Type")
#ggsave("Box_MinNights_RoomType.png", dpi=1000)
data_cut = data_sample_final[data_sample_final$price<=1000,]
for (i in 1:length(neighbourhood_groups)) {
NG = as.character(NG_centers[i,1])
data = data_cut[data_cut$neighbourhood_group == NG,]
centerlong = (min(data$longitude) + max(data$longitude))/2
centerlat = (min(data$latitude) + max(data$latitude))/2
map = get_map(location = c(centerlong, centerlat),
source = "google",
zoom = 11,
maptype = "roadmap",
size = c(640, 640),
scale = 2)
print(ggmap(map)
+ geom_point(data = data[data$price<=500,],
aes(x = data$longitude[data$price<=500],
y = data$latitude[data$price<=500],
colour = data$price[data$price<=500]
),
shape = 1, size = 1)
+ geom_point(data = data[data$price>500,],
aes(x = data$longitude[data$price>500],
y = data$latitude[data$price>500],
colour = data$price[data$price>500]
),
shape = 1, size = 1)
+ scale_colour_distiller(palette = "Spectral")
+ labs(x = "Longitude",
y = "Latitude",
colour="Price",
title = NG)
)
print(cat('\n'))
}
library(ggmap)
library(dplyr)
library("ggcorrplot")
library(gridExtra)
#library(ggplot)
library(plotrix)
register_google("AIzaSyBizy0qq2Lq2IHZqp76GfUq6VSb5er4pt0")
register_google("AIzaSyBizy0qq2Lq2IHZqp76GfUq6VSb5er4pt0")
library(ggmap)
library(dplyr)
library("ggcorrplot")
library(gridExtra)
#library(ggplot)
library(plotrix)
map = get_map(location = c(ALL_centerlong, ALL_centerlat),
source = "google",
zoom = 10,
maptype = "roadmap",
size = c(640, 640),
scale = 2)
get_map(
)
get_map()
library(ggmap)
install library(ggmap)
install.packages(ggmap)
